{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "image = img_to_array(load_img('train/timg4.jpg'))\n",
    "image = np.array(image, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "from skimage import transform,data\n",
    "image = transform.resize(image, (400, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rgb2lab(1.0/255*image)[:,:,0]\n",
    "Y = rgb2lab(1.0/255*image)[:,:,1:]\n",
    "Y /= 128\n",
    "X = X.reshape(1, 400, 400, 1)\n",
    "Y = Y.reshape(1, 400, 400, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None, 1)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish model\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0378\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0073\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0062\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0058\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0057\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0056\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0056\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0053\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0053\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0051\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0049\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0048\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0046\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0045\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0043\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0039\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0037\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0032\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0031\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0031\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0029\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0029\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0029\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0028\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0028\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0028\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0026\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026\n",
      "Epoch 53/1000\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X, \n",
    "    y=Y,\n",
    "    batch_size=1,\n",
    "    epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 333ms/step\n",
      "0.00039919823757372797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X, Y, batch_size=1))\n",
    "output = model.predict(X)\n",
    "output *= 128\n",
    "# Output colorizations\n",
    "cur = np.zeros((400, 400, 3))\n",
    "cur[:,:,0] = X[0][:,:,0]\n",
    "cur[:,:,1:] = output[0]\n",
    "imsave(\"img_result.png\", lab2rgb(cur))\n",
    "imsave(\"img_gray_version.png\", rgb2gray(lab2rgb(cur)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform,data\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = img_to_array(load_img('test/img3.jpg'))\n",
    "image_x = np.array(image_x, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片原始维度为600,600\n"
     ]
    }
   ],
   "source": [
    "ll_1 = len(image_x[1])\n",
    "ll_2 = len(image_x[2])\n",
    "print(\"图片原始维度为({},{})\".format(ll_1, ll_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "dst = transform.resize(image_x, (400, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画图\n",
    "plt.figure('resize')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('before resize')\n",
    "plt.imshow(image_x,plt.cm.gray)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('before resize')\n",
    "plt.imshow(dst,plt.cm.gray)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = rgb2lab(1.0/255*dst)[:,:,0]\n",
    "Y_2 = rgb2lab(1.0/255*dst)[:,:,1:]\n",
    "Y_2 /= 128\n",
    "X_2 = X_2.reshape(1, 400, 400, 1)\n",
    "Y_2 = Y_2.reshape(1, 400, 400, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = model.predict(X_2)\n",
    "output *= 128\n",
    "# Output colorizations\n",
    "cur = np.zeros((400, 400, 3))\n",
    "cur[:,:,0] = X_2[0][:,:,0]\n",
    "cur[:,:,1:] = output[0]\n",
    "#imsave(\"img_result_2.png\", lab2rgb(cur))\n",
    "#imsave(\"img_gray_version_2.png\", rgb2gray(lab2rgb(cur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "D:\\Anaconda3\\envs\\tensorFlow\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "#把维度拉回来\n",
    "dst=transform.resize(cur, (ll_1, ll_2))\n",
    "imsave(\"img_result_3.png\", lab2rgb(dst))\n",
    "imsave(\"img_gray_version_3.png\", rgb2gray(lab2rgb(dst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
